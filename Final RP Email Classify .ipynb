{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e88b7f8-890b-47fe-b2e7-eaf2bcbdadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1d09833-c475-4a52-b1db-dc49488cda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with proper encoding\n",
    "df = pd.read_excel(r'E:\\OM Research Project\\Combined_Data.xlsx', engine='openpyxl')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f14ec59e-f1f0-4e03-94b6-f24c820f2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Remove punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84b11bef-f95f-4f60-b6ca-a01ff521b2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 19 Nov 2024 08:13:09 +0000 (UTC)</td>\n",
       "      <td>Career Navigator 2024* &lt;newsletters-noreply@li...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Infosys Walk-In for IT Operations | 21st Nov 2024</td>\n",
       "      <td>Career Navigator 2024*By AMISHA BHATTBy AMISHA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed, 20 Nov 2024 06:13:07 +0000 (UTC)</td>\n",
       "      <td>Work From Home Jobs &lt;newsletters-noreply@linke...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Genpact Jobs Gurgaon for Freshers| Best Opport...</td>\n",
       "      <td>Work From Home JobsBy Work From Home/ Experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, 19 Nov 2024 06:13:07 +0000 (UTC)</td>\n",
       "      <td>Work From Home Jobs &lt;newsletters-noreply@linke...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Genpact Jobs Noida for Freshers| Best Opportun...</td>\n",
       "      <td>Work From Home JobsBy Work From Home/ Experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon, 18 Nov 2024 14:33:15 +0000 (UTC)</td>\n",
       "      <td>LinkedIn &lt;updates-noreply@linkedin.com&gt;</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Vaibhav Kadam just posted something that might...</td>\n",
       "      <td>----------------------------------------      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Date  \\\n",
       "0  Tue, 19 Nov 2024 08:13:09 +0000 (UTC)   \n",
       "1  Wed, 20 Nov 2024 06:13:07 +0000 (UTC)   \n",
       "2  Tue, 19 Nov 2024 06:13:07 +0000 (UTC)   \n",
       "3  Mon, 18 Nov 2024 14:33:15 +0000 (UTC)   \n",
       "\n",
       "                                                From  \\\n",
       "0  Career Navigator 2024* <newsletters-noreply@li...   \n",
       "1  Work From Home Jobs <newsletters-noreply@linke...   \n",
       "2  Work From Home Jobs <newsletters-noreply@linke...   \n",
       "3            LinkedIn <updates-noreply@linkedin.com>   \n",
       "\n",
       "                                   To  \\\n",
       "0  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "1  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "2  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "3  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "\n",
       "                                             Subject  \\\n",
       "0  Infosys Walk-In for IT Operations | 21st Nov 2024   \n",
       "1  Genpact Jobs Gurgaon for Freshers| Best Opport...   \n",
       "2  Genpact Jobs Noida for Freshers| Best Opportun...   \n",
       "3  Vaibhav Kadam just posted something that might...   \n",
       "\n",
       "                                                Body  \n",
       "0  Career Navigator 2024*By AMISHA BHATTBy AMISHA...  \n",
       "1  Work From Home JobsBy Work From Home/ Experien...  \n",
       "2  Work From Home JobsBy Work From Home/ Experien...  \n",
       "3  ----------------------------------------      ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab828167-67f2-4021-8f4e-dd866bf75316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['Body'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efbe9fe8-2a4a-44d5-b96a-0bada918832d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32016, 6)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ffbdfde-ec8b-4efb-af92-5527167ef96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              0\n",
       "From              0\n",
       "To                0\n",
       "Subject           0\n",
       "Body              0\n",
       "processed_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15946e5f-39f1-4238-9de4-e078a93d7401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32016 entries, 0 to 55435\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Date            32016 non-null  object\n",
      " 1   From            32016 non-null  object\n",
      " 2   To              32016 non-null  object\n",
      " 3   Subject         32016 non-null  object\n",
      " 4   Body            32016 non-null  object\n",
      " 5   processed_text  32016 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f6401ba-b23c-4aed-a79c-5baa4fe9058d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              object\n",
       "From              object\n",
       "To                object\n",
       "Subject           object\n",
       "Body              object\n",
       "processed_text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bca7510e-3c50-4720-a026-e2cd967ba473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Error importing TensorFlow: No module named 'tensorflow'\n",
      "Please ensure TensorFlow is installed correctly and is compatible with your system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.10.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0)\n",
      "ERROR: No matching distribution found for tensorflow==2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Ensure TensorFlow is installed\n",
    "%pip install tensorflow==2.10.0\n",
    "\n",
    "# Ensure TensorFlow is imported correctly\n",
    "try:\n",
    "\tfrom tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\tfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\t# Tokenization for LSTM\n",
    "\ttokenizer = Tokenizer(num_words=5000)\n",
    "\ttokenizer.fit_on_texts(df['processed_text'])\n",
    "\tsequences = tokenizer.texts_to_sequences(df['processed_text'])\n",
    "\tX_lstm = pad_sequences(sequences, maxlen=50)\n",
    "except ImportError as e:\n",
    "\tprint(\"Error importing TensorFlow:\", e)\n",
    "\tprint(\"Please ensure TensorFlow is installed correctly and is compatible with your system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b125a90-aabd-49c5-b96e-87810ae3e79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (55436, 5)\n",
      "                                    Date  \\\n",
      "0  Tue, 19 Nov 2024 08:13:09 +0000 (UTC)   \n",
      "1  Wed, 20 Nov 2024 06:13:07 +0000 (UTC)   \n",
      "2  Tue, 19 Nov 2024 06:13:07 +0000 (UTC)   \n",
      "3  Mon, 18 Nov 2024 14:33:15 +0000 (UTC)   \n",
      "4  Fri, 29 Nov 2024 01:50:12 +0000 (UTC)   \n",
      "\n",
      "                                                From  \\\n",
      "0  Career Navigator 2024* <newsletters-noreply@li...   \n",
      "1  Work From Home Jobs <newsletters-noreply@linke...   \n",
      "2  Work From Home Jobs <newsletters-noreply@linke...   \n",
      "3            LinkedIn <updates-noreply@linkedin.com>   \n",
      "4      Aarushi from foundit <info@alerts.foundit.in>   \n",
      "\n",
      "                                   To  \\\n",
      "0  Ajay Mane <ajaymane5885@gmail.com>   \n",
      "1  Ajay Mane <ajaymane5885@gmail.com>   \n",
      "2  Ajay Mane <ajaymane5885@gmail.com>   \n",
      "3  Ajay Mane <ajaymane5885@gmail.com>   \n",
      "4              ajaymane5885@gmail.com   \n",
      "\n",
      "                                             Subject  \\\n",
      "0  Infosys Walk-In for IT Operations | 21st Nov 2024   \n",
      "1  Genpact Jobs Gurgaon for Freshers| Best Opport...   \n",
      "2  Genpact Jobs Noida for Freshers| Best Opportun...   \n",
      "3  Vaibhav Kadam just posted something that might...   \n",
      "4             Hunt for jobs the right way, Jobseeker   \n",
      "\n",
      "                                                Body  \n",
      "0  Career Navigator 2024*By AMISHA BHATTBy AMISHA...  \n",
      "1  Work From Home JobsBy Work From Home/ Experien...  \n",
      "2  Work From Home JobsBy Work From Home/ Experien...  \n",
      "3  ----------------------------------------      ...  \n",
      "4  <!DOCTYPE html><html xmlns:v=\"urn:schemas-micr...  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset with proper encoding\n",
    "df = pd.read_excel(r'E:\\OM Research Project\\Combined_Data.xlsx')\n",
    "\n",
    "# Print dataset size\n",
    "print(\"Dataset Shape:\", df.shape)  # Should print (578, X) if all rows are loaded\n",
    "print(df.head())  # Show first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7dcaf0a6-b021-4cf2-ac25-6fd3535ce47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows in Dataset: 55436\n",
      "                                             Subject  \\\n",
      "0  Infosys Walk-In for IT Operations | 21st Nov 2024   \n",
      "1  Genpact Jobs Gurgaon for Freshers| Best Opport...   \n",
      "2  Genpact Jobs Noida for Freshers| Best Opportun...   \n",
      "3  Vaibhav Kadam just posted something that might...   \n",
      "4             Hunt for jobs the right way, Jobseeker   \n",
      "\n",
      "                                                Body  category  \n",
      "0  Career Navigator 2024*By AMISHA BHATTBy AMISHA...         1  \n",
      "1  Work From Home JobsBy Work From Home/ Experien...         1  \n",
      "2  Work From Home JobsBy Work From Home/ Experien...         1  \n",
      "3  ----------------------------------------      ...         1  \n",
      "4  <!DOCTYPE html><html xmlns:v=\"urn:schemas-micr...         1  \n",
      "Total Rows Classified: 55436\n"
     ]
    }
   ],
   "source": [
    "# Check if the dataset is loading properly\n",
    "print(\"Total Rows in Dataset:\", df.shape[0])\n",
    "\n",
    "# Define spam keywords\n",
    "spam_keywords = [\"unsubscribe\", \"win\", \"click here\", \"free\", \"claim\", \"urgent\", \"limited offer\", \n",
    "                     \"winner\", \"guaranteed\", \"risk-free\", \"exclusive\", \"money\", \"claim your prize\", \n",
    "                     \"offer expires\", \"free trial\", \"credit card\", \"cash prize\", \"unsecured\", \"no payment required\"]\n",
    "\n",
    "\n",
    "# Function to classify emails\n",
    "def classify_email(text):\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"ham\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    if any(word in text for word in spam_keywords):\n",
    "        return \"spam\"\n",
    "    return \"ham\"\n",
    "\n",
    "# Apply classification to ALL rows (not just one row)\n",
    "df[\"category\"] = df.apply(lambda row: classify_email(str(row[\"Subject\"]) + \" \" + str(row[\"Body\"])), axis=1)\n",
    "\n",
    "# Convert category to numerical (ham=0, spam=1)\n",
    "df[\"category\"] = df[\"category\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "# Verify all rows are classified\n",
    "print(df[[\"Subject\", \"Body\", \"category\"]].head())  # Show first few rows\n",
    "print(\"Total Rows Classified:\", df.shape[0])  # Should be 578+ rows\n",
    "\n",
    "# Save the classified dataset\n",
    "df.to_csv(\"classified_emails.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "882f7051-7bc7-4ab6-b796-afd2bab106a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "1    32790\n",
       "0    22646\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "48b12115-1970-4618-b68b-324a48cb8a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 19 Nov 2024 08:13:09 +0000 (UTC)</td>\n",
       "      <td>Career Navigator 2024* &lt;newsletters-noreply@li...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Infosys Walk-In for IT Operations | 21st Nov 2024</td>\n",
       "      <td>Career Navigator 2024*By AMISHA BHATTBy AMISHA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed, 20 Nov 2024 06:13:07 +0000 (UTC)</td>\n",
       "      <td>Work From Home Jobs &lt;newsletters-noreply@linke...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Genpact Jobs Gurgaon for Freshers| Best Opport...</td>\n",
       "      <td>Work From Home JobsBy Work From Home/ Experien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, 19 Nov 2024 06:13:07 +0000 (UTC)</td>\n",
       "      <td>Work From Home Jobs &lt;newsletters-noreply@linke...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Genpact Jobs Noida for Freshers| Best Opportun...</td>\n",
       "      <td>Work From Home JobsBy Work From Home/ Experien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon, 18 Nov 2024 14:33:15 +0000 (UTC)</td>\n",
       "      <td>LinkedIn &lt;updates-noreply@linkedin.com&gt;</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Vaibhav Kadam just posted something that might...</td>\n",
       "      <td>----------------------------------------      ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri, 29 Nov 2024 01:50:12 +0000 (UTC)</td>\n",
       "      <td>Aarushi from foundit &lt;info@alerts.foundit.in&gt;</td>\n",
       "      <td>ajaymane5885@gmail.com</td>\n",
       "      <td>Hunt for jobs the right way, Jobseeker</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html xmlns:v=\"urn:schemas-micr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Date  \\\n",
       "0  Tue, 19 Nov 2024 08:13:09 +0000 (UTC)   \n",
       "1  Wed, 20 Nov 2024 06:13:07 +0000 (UTC)   \n",
       "2  Tue, 19 Nov 2024 06:13:07 +0000 (UTC)   \n",
       "3  Mon, 18 Nov 2024 14:33:15 +0000 (UTC)   \n",
       "4  Fri, 29 Nov 2024 01:50:12 +0000 (UTC)   \n",
       "\n",
       "                                                From  \\\n",
       "0  Career Navigator 2024* <newsletters-noreply@li...   \n",
       "1  Work From Home Jobs <newsletters-noreply@linke...   \n",
       "2  Work From Home Jobs <newsletters-noreply@linke...   \n",
       "3            LinkedIn <updates-noreply@linkedin.com>   \n",
       "4      Aarushi from foundit <info@alerts.foundit.in>   \n",
       "\n",
       "                                   To  \\\n",
       "0  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "1  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "2  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "3  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "4              ajaymane5885@gmail.com   \n",
       "\n",
       "                                             Subject  \\\n",
       "0  Infosys Walk-In for IT Operations | 21st Nov 2024   \n",
       "1  Genpact Jobs Gurgaon for Freshers| Best Opport...   \n",
       "2  Genpact Jobs Noida for Freshers| Best Opportun...   \n",
       "3  Vaibhav Kadam just posted something that might...   \n",
       "4             Hunt for jobs the right way, Jobseeker   \n",
       "\n",
       "                                                Body  category  \n",
       "0  Career Navigator 2024*By AMISHA BHATTBy AMISHA...         1  \n",
       "1  Work From Home JobsBy Work From Home/ Experien...         1  \n",
       "2  Work From Home JobsBy Work From Home/ Experien...         1  \n",
       "3  ----------------------------------------      ...         1  \n",
       "4  <!DOCTYPE html><html xmlns:v=\"urn:schemas-micr...         1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a27fcecb-e33b-4f4f-9dc9-24d471dd8929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 19 Nov 2024 08:13:09 +0000 (UTC)</td>\n",
       "      <td>Career Navigator 2024* &lt;newsletters-noreply@li...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Infosys Walk-In for IT Operations | 21st Nov 2024</td>\n",
       "      <td>Career Navigator 2024*By AMISHA BHATTBy AMISHA...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed, 20 Nov 2024 06:13:07 +0000 (UTC)</td>\n",
       "      <td>Work From Home Jobs &lt;newsletters-noreply@linke...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Genpact Jobs Gurgaon for Freshers| Best Opport...</td>\n",
       "      <td>Work From Home JobsBy Work From Home/ Experien...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, 19 Nov 2024 06:13:07 +0000 (UTC)</td>\n",
       "      <td>Work From Home Jobs &lt;newsletters-noreply@linke...</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Genpact Jobs Noida for Freshers| Best Opportun...</td>\n",
       "      <td>Work From Home JobsBy Work From Home/ Experien...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon, 18 Nov 2024 14:33:15 +0000 (UTC)</td>\n",
       "      <td>LinkedIn &lt;updates-noreply@linkedin.com&gt;</td>\n",
       "      <td>Ajay Mane &lt;ajaymane5885@gmail.com&gt;</td>\n",
       "      <td>Vaibhav Kadam just posted something that might...</td>\n",
       "      <td>----------------------------------------      ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri, 29 Nov 2024 01:50:12 +0000 (UTC)</td>\n",
       "      <td>Aarushi from foundit &lt;info@alerts.foundit.in&gt;</td>\n",
       "      <td>ajaymane5885@gmail.com</td>\n",
       "      <td>Hunt for jobs the right way, Jobseeker</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html xmlns:v=\"urn:schemas-micr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Date  \\\n",
       "0  Tue, 19 Nov 2024 08:13:09 +0000 (UTC)   \n",
       "1  Wed, 20 Nov 2024 06:13:07 +0000 (UTC)   \n",
       "2  Tue, 19 Nov 2024 06:13:07 +0000 (UTC)   \n",
       "3  Mon, 18 Nov 2024 14:33:15 +0000 (UTC)   \n",
       "4  Fri, 29 Nov 2024 01:50:12 +0000 (UTC)   \n",
       "\n",
       "                                                From  \\\n",
       "0  Career Navigator 2024* <newsletters-noreply@li...   \n",
       "1  Work From Home Jobs <newsletters-noreply@linke...   \n",
       "2  Work From Home Jobs <newsletters-noreply@linke...   \n",
       "3            LinkedIn <updates-noreply@linkedin.com>   \n",
       "4      Aarushi from foundit <info@alerts.foundit.in>   \n",
       "\n",
       "                                   To  \\\n",
       "0  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "1  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "2  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "3  Ajay Mane <ajaymane5885@gmail.com>   \n",
       "4              ajaymane5885@gmail.com   \n",
       "\n",
       "                                             Subject  \\\n",
       "0  Infosys Walk-In for IT Operations | 21st Nov 2024   \n",
       "1  Genpact Jobs Gurgaon for Freshers| Best Opport...   \n",
       "2  Genpact Jobs Noida for Freshers| Best Opportun...   \n",
       "3  Vaibhav Kadam just posted something that might...   \n",
       "4             Hunt for jobs the right way, Jobseeker   \n",
       "\n",
       "                                                Body  category Label  \n",
       "0  Career Navigator 2024*By AMISHA BHATTBy AMISHA...         1  Spam  \n",
       "1  Work From Home JobsBy Work From Home/ Experien...         1  Spam  \n",
       "2  Work From Home JobsBy Work From Home/ Experien...         1  Spam  \n",
       "3  ----------------------------------------      ...         1  Spam  \n",
       "4  <!DOCTYPE html><html xmlns:v=\"urn:schemas-micr...         1  Spam  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to automatically label emails based on keywords\n",
    "def auto_label(subject, body):\n",
    "    # Convert to lowercase for uniformity\n",
    "    subject = str(subject).lower()\n",
    "    body = str(body).lower()\n",
    "    \n",
    "\n",
    "    # Spam keywords\n",
    "    spam_keywords = [\"unsubscribe\", \"win\", \"click here\", \"free\", \"claim\", \"urgent\", \"limited offer\", \n",
    "                     \"winner\", \"guaranteed\", \"risk-free\", \"exclusive\", \"money\", \"claim your prize\", \n",
    "                     \"offer expires\", \"free trial\", \"credit card\", \"cash prize\", \"unsecured\", \"no payment required\"]\n",
    "    if any(keyword in subject or keyword in body for keyword in spam_keywords):\n",
    "        return \"Spam\"\n",
    "\n",
    "    # Promotion keywords\n",
    "    promo_keywords = [\"offer\", \"deal\", \"discount\", \"sale\", \"coupon\", \"promo\", \"clearance\", \"bargain\", \n",
    "                      \"flash sale\", \"hot deal\", \"special offer\", \"limited time\", \"today only\", \"big discount\", \n",
    "                      \"buy now\", \"shop today\", \"online exclusive\", \"exclusive deal\", \"seasonal sale\"]\n",
    "    if any(keyword in subject or keyword in body for keyword in promo_keywords):\n",
    "        return \"Promotion\"\n",
    "\n",
    "    # Social keywords\n",
    "    social_keywords = [\"friend request\", \"like\", \"comment\", \"follow\", \"connection\", \"new follower\", \n",
    "                       \"your post\", \"social invite\", \"message request\", \"share your status\", \"new like\", \n",
    "                       \"new comment\", \"friend suggestion\", \"tagged in photo\", \"social media update\", \n",
    "                       \"profile update\", \"join the group\"]\n",
    "    if any(keyword in subject or keyword in body for keyword in social_keywords):\n",
    "        return \"Social\"\n",
    "\n",
    "    # Update keywords\n",
    "    update_keywords = [\"update\", \"newsletter\", \"report\", \"summary\", \"digest\", \"alert\", \"news\", \n",
    "                       \"update notification\", \"policy update\", \"account update\", \"system update\", \"upgrade\", \n",
    "                       \"change\", \"announcement\", \"new feature\", \"release notes\", \"latest news\"]\n",
    "    if any(keyword in subject or keyword in body for keyword in update_keywords):\n",
    "        return \"Updates\"\n",
    "\n",
    "    # Default to Primary (Ham)\n",
    "    return \"Primary\"\n",
    "\n",
    "# Apply the automatic labeling function\n",
    "df['Label'] = df.apply(lambda row: auto_label(row['Subject'], row['Body']), axis=1)\n",
    "\n",
    "# Display some labeled data samples to verify\n",
    "df[['From', 'Subject', 'Body', 'Label']].head(20)\n",
    "# Display the updated dataset with the new labels\n",
    "# Create a new dataframe with the new column 'Label'\n",
    "df1 = df.copy()\n",
    "\n",
    "# Display the updated dataset with the new labels\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8192613-a103-4b63-a9ac-ea549e83d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Spam         32790\n",
       "Primary      15784\n",
       "Updates       2507\n",
       "Promotion     2281\n",
       "Social        2074\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63d0ca84-116d-4712-85e4-1c6aea1a6da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04bb3d80-8f66-4984-b1c2-537cecb27893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "df['processed_text'] = df['Body'].apply(preprocess_text)  # Ensure correct column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b662df0f-a6a1-40dd-8b2a-b11345c2fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "316e98df-ea95-4b49-b38f-4b7e4f4862d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55436, 677732)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f69babe6-c0a0-4d88-9f88-c489326eb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8ef45779-2fc2-489b-a054-5f886b18eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Spam', 'Spam', 'Spam', ..., 'Spam', 'Primary', 'Spam'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d311190-c718-4ede-99a6-c2d70a9bf92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Subject  \\\n",
      "0  Congratulations! You won a cash prize   \n",
      "1       Flash Sale - 50% OFF today only!   \n",
      "2            Your friend liked your post   \n",
      "3               Weekly newsletter update   \n",
      "4           Meeting scheduled for Monday   \n",
      "\n",
      "                                                Body      Label  \n",
      "0  Click here to claim your prize. No payment req...       Spam  \n",
      "1  Don't miss our hot deal! Limited time offer, s...  Promotion  \n",
      "2  John commented on your post. View it on your p...     Social  \n",
      "3  Here is your weekly newsletter with all the la...    Updates  \n",
      "4  Reminder: Team meeting is scheduled for 10 AM ...    Primary  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample email data (replace with your actual data or load from Excel)\n",
    "data = {\n",
    "    'Subject': [\n",
    "        \"Congratulations! You won a cash prize\", \n",
    "        \"Flash Sale - 50% OFF today only!\", \n",
    "        \"Your friend liked your post\", \n",
    "        \"Weekly newsletter update\", \n",
    "        \"Meeting scheduled for Monday\"\n",
    "    ],\n",
    "    'Body': [\n",
    "        \"Click here to claim your prize. No payment required.\",\n",
    "        \"Don't miss our hot deal! Limited time offer, shop now.\",\n",
    "        \"John commented on your post. View it on your profile.\",\n",
    "        \"Here is your weekly newsletter with all the latest news.\",\n",
    "        \"Reminder: Team meeting is scheduled for 10 AM Monday.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define keyword lists\n",
    "spam_keywords = [\n",
    "    \"unsubscribe\", \"win\", \"click here\", \"free\", \"claim\", \"urgent\", \"limited offer\", \n",
    "    \"winner\", \"guaranteed\", \"risk-free\", \"exclusive\", \"money\", \"claim your prize\", \n",
    "    \"offer expires\", \"free trial\", \"credit card\", \"cash prize\", \"unsecured\", \n",
    "    \"no payment required\"\n",
    "]\n",
    "\n",
    "promo_keywords = [\n",
    "    \"offer\", \"deal\", \"discount\", \"sale\", \"coupon\", \"promo\", \"clearance\", \"bargain\", \n",
    "    \"flash sale\", \"hot deal\", \"special offer\", \"limited time\", \"today only\", \n",
    "    \"big discount\", \"buy now\", \"shop today\", \"online exclusive\", \"exclusive deal\", \n",
    "    \"seasonal sale\"\n",
    "]\n",
    "\n",
    "social_keywords = [\n",
    "    \"friend request\", \"like\", \"comment\", \"follow\", \"connection\", \"new follower\", \n",
    "    \"your post\", \"social invite\", \"message request\", \"share your status\", \"new like\", \n",
    "    \"new comment\", \"friend suggestion\", \"tagged in photo\", \"social media update\", \n",
    "    \"profile update\", \"join the group\"\n",
    "]\n",
    "\n",
    "update_keywords = [\n",
    "    \"update\", \"newsletter\", \"report\", \"summary\", \"digest\", \"alert\", \"news\", \n",
    "    \"update notification\", \"policy update\", \"account update\", \"system update\", \n",
    "    \"upgrade\", \"change\", \"announcement\", \"new feature\", \"release notes\", \"latest news\"\n",
    "]\n",
    "\n",
    "primary_keywords = [\n",
    "    \"meeting\", \"appointment\", \"invoice\", \"schedule\", \"reminder\", \"password\", \n",
    "    \"receipt\", \"confirmation\", \"team\", \"project\", \"task\", \"follow-up\"\n",
    "]\n",
    "\n",
    "# Function to classify emails\n",
    "def classify_email(subject, body):\n",
    "    if not isinstance(subject, str):\n",
    "        subject = ''\n",
    "    if not isinstance(body, str):\n",
    "        body = ''\n",
    "    \n",
    "    content = (subject + ' ' + body).lower()\n",
    "    \n",
    "    if any(keyword in content for keyword in spam_keywords):\n",
    "        return \"Spam\"\n",
    "    elif any(keyword in content for keyword in promo_keywords):\n",
    "        return \"Promotion\"\n",
    "    elif any(keyword in content for keyword in social_keywords):\n",
    "        return \"Social\"\n",
    "    elif any(keyword in content for keyword in update_keywords):\n",
    "        return \"Updates\"\n",
    "    elif any(keyword in content for keyword in primary_keywords):\n",
    "        return \"Primary\"\n",
    "    else:\n",
    "        return \"Primary\"  # default fallback\n",
    "\n",
    "# Apply classification\n",
    "df['Label'] = df.apply(lambda row: classify_email(row['Subject'], row['Body']), axis=1)\n",
    "\n",
    "# Display results\n",
    "print(df[['Subject', 'Body', 'Label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8d8f31cd-f23c-4cd3-93a3-4707f1fd04cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Subject  \\\n",
      "0      Infosys Walk-In for IT Operations | 21st Nov 2024   \n",
      "1      Genpact Jobs Gurgaon for Freshers| Best Opport...   \n",
      "2      Genpact Jobs Noida for Freshers| Best Opportun...   \n",
      "3      Vaibhav Kadam just posted something that might...   \n",
      "4                 Hunt for jobs the right way, Jobseeker   \n",
      "...                                                  ...   \n",
      "55424  Kishor Khatau Thacker shared \"Dignitaries Accl...   \n",
      "55426  Dear Sanjay Devgonda Patil, aim to diversify y...   \n",
      "55428  Top 6 posts on Facebook: posts from Raju Patil...   \n",
      "55429  vir sanghvi posted: If this guy was a Palestin...   \n",
      "55435  Lets OTT Tweeted: #ItluMaredumilliPrajaneekam ...   \n",
      "\n",
      "                                                    Body Label  \n",
      "0      Career Navigator 2024*By AMISHA BHATTBy AMISHA...  Spam  \n",
      "1      Work From Home JobsBy Work From Home/ Experien...  Spam  \n",
      "2      Work From Home JobsBy Work From Home/ Experien...  Spam  \n",
      "3      ----------------------------------------      ...  Spam  \n",
      "4      <!DOCTYPE html><html xmlns:v=\"urn:schemas-micr...  Spam  \n",
      "...                                                  ...   ...  \n",
      "55424  What's happeningKishor Khatau Thacker sharedKi...  Spam  \n",
      "55426  ----------------------------------------------...  Spam  \n",
      "55428  Hi Sanjay,\"आमचे मार्गदर्शक मित्र स्वाभिमानी शे...  Spam  \n",
      "55429  Your Highlightsvir sanghvi - @virsanghviIf thi...  Spam  \n",
      "55435  Your HighlightsLets OTT - @IetsOTT#ItluMaredum...  Spam  \n",
      "\n",
      "[32016 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset with proper encoding\n",
    "df = pd.read_excel(r'E:\\OM Research Project\\Combined_Data.xlsx', engine='openpyxl')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define keyword lists\n",
    "spam_keywords = [\n",
    "    \"unsubscribe\", \"win\", \"click here\", \"free\", \"claim\", \"urgent\", \"limited offer\", \n",
    "    \"winner\", \"guaranteed\", \"risk-free\", \"exclusive\", \"money\", \"claim your prize\", \n",
    "    \"offer expires\", \"free trial\", \"credit card\", \"cash prize\", \"unsecured\", \n",
    "    \"no payment required\"\n",
    "]\n",
    "\n",
    "promo_keywords = [\n",
    "    \"offer\", \"deal\", \"discount\", \"sale\", \"coupon\", \"promo\", \"clearance\", \"bargain\", \n",
    "    \"flash sale\", \"hot deal\", \"special offer\", \"limited time\", \"today only\", \n",
    "    \"big discount\", \"buy now\", \"shop today\", \"online exclusive\", \"exclusive deal\", \n",
    "    \"seasonal sale\"\n",
    "]\n",
    "\n",
    "social_keywords = [\n",
    "    \"friend request\", \"like\", \"comment\", \"follow\", \"connection\", \"new follower\", \n",
    "    \"your post\", \"social invite\", \"message request\", \"share your status\", \"new like\", \n",
    "    \"new comment\", \"friend suggestion\", \"tagged in photo\", \"social media update\", \n",
    "    \"profile update\", \"join the group\"\n",
    "]\n",
    "\n",
    "update_keywords = [\n",
    "    \"update\", \"newsletter\", \"report\", \"summary\", \"digest\", \"alert\", \"news\", \n",
    "    \"update notification\", \"policy update\", \"account update\", \"system update\", \n",
    "    \"upgrade\", \"change\", \"announcement\", \"new feature\", \"release notes\", \"latest news\"\n",
    "]\n",
    "\n",
    "primary_keywords = [\n",
    "    \"meeting\", \"appointment\", \"invoice\", \"schedule\", \"reminder\", \"password\", \n",
    "    \"receipt\", \"confirmation\", \"team\", \"project\", \"task\", \"follow-up\"\n",
    "]\n",
    "\n",
    "# Function to classify emails\n",
    "def classify_email(subject, body):\n",
    "    if not isinstance(subject, str):\n",
    "        subject = ''\n",
    "    if not isinstance(body, str):\n",
    "        body = ''\n",
    "    \n",
    "    content = (subject + ' ' + body).lower()\n",
    "    \n",
    "    if any(keyword in content for keyword in spam_keywords):\n",
    "        return \"Spam\"\n",
    "    elif any(keyword in content for keyword in promo_keywords):\n",
    "        return \"Promotion\"\n",
    "    elif any(keyword in content for keyword in social_keywords):\n",
    "        return \"Social\"\n",
    "    elif any(keyword in content for keyword in update_keywords):\n",
    "        return \"Updates\"\n",
    "    elif any(keyword in content for keyword in primary_keywords):\n",
    "        return \"Primary\"\n",
    "    else:\n",
    "        return \"Primary\"  # default fallback\n",
    "\n",
    "# Apply classification\n",
    "df['Label'] = df.apply(lambda row: classify_email(row['Subject'], row['Body']), axis=1)\n",
    "\n",
    "# Display results\n",
    "print(df[['Subject', 'Body', 'Label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e5bda0c3-b07e-4a98-b5ad-a6306a585beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Spam         25094\n",
       "Primary       3457\n",
       "Promotion     1419\n",
       "Updates       1388\n",
       "Social         658\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a99298-6407-4f2e-81cf-dc20a31dc466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
